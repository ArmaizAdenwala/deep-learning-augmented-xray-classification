{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSC 177 Final Project - Medical Data",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmjX4AmXYbvq"
      },
      "source": [
        "# Medical Data\n",
        "\n",
        "Armaiz Adenwala\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM_6E2CBYyKo"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Lorem ipsum dolor sit amet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnkLGSH9Ysti"
      },
      "source": [
        "## Creating Artificial X-Ray Scans Using a GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxwCOc-rY7Gb"
      },
      "source": [
        "### Setting Up The Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HTLaRCKYqzH"
      },
      "source": [
        "import os\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PEWoCHRZGgp"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TBi9qyPZKtm"
      },
      "source": [
        "#### Downloading the Dataset\n",
        "\n",
        "The dataset is hosted on kaggle, we will use the kaggle api to download this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5fdoeAUY6At"
      },
      "source": [
        " ! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D1JQTxhaOp4"
      },
      "source": [
        "Please upload your `kaggle.json` file here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUXWzBOjZJ45"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8llgTL87amWT"
      },
      "source": [
        "We will then need to setup the kaggle api config manually in the home directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ay3Pmd2af-Z"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwigZMYVauBA"
      },
      "source": [
        "This will downloaad the chest-xray-pneumonia dataset from kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1L8C1tOar2d"
      },
      "source": [
        "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBvud5BZa0Vi"
      },
      "source": [
        "#### Organize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5l-xycXbGPz"
      },
      "source": [
        "We will now need to unzip the data into a dataset folder. We will then create two dataset folders. One for xray scans of patients that are healthy, and one for xray scans of patients with pneumonia. This is simply to keep everything organized without having it deeply nested in the dataset folder. Additionally, the dataloader pulls from the subfolders, so we will need to split NORMAL and PNEUMONIA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jiNkMTqayhh"
      },
      "source": [
        "! mkdir dataset\n",
        "! unzip chest-xray-pneumonia.zip -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8D8W-ubcnJn"
      },
      "source": [
        "We will then recursively copy over the image files into the new seperate folders to allow `ImageFolder` to load specifically normal or speicifcally pneumonia xrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4eV1KwwchRn"
      },
      "source": [
        "! mkdir ./dataset/chest_xray/chest_xray_normal\n",
        "! mkdir ./dataset/chest_xray/chest_xray_pneumonia\n",
        "! cp -r ./dataset/chest_xray/chest_xray/train/NORMAL ./dataset/chest_xray/chest_xray_normal/train\n",
        "! cp -r ./dataset/chest_xray/chest_xray/train/PNEUMONIA ./dataset/chest_xray/chest_xray_pneumonia/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySKkbx9dO01"
      },
      "source": [
        "As we prepare the data, we need to specify a few key variables.\n",
        "\n",
        "`batch_size` refers to ____. \n",
        "\n",
        "\n",
        "Image size refers to the size we want our images to be. Due to limited GPU resources, 64x64 is common, however, we will use 128x128 to retain as much detail as we can.\n",
        "\n",
        "Stats is used to normalize the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDDCV3LUcK51"
      },
      "source": [
        "batch_size = 128\n",
        "image_size = 128\n",
        "stats = (0.5), (0.5)\n",
        "images_count = 64\n",
        "images_row_count = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIulu0sPd8CG"
      },
      "source": [
        "We use `ImageFolder` to load the datasets and apply the following transformations:\n",
        "* resize the images to height/width of 128px\n",
        "* crop the images to become exactly 128x128\n",
        "* reduce images to 1 channel / grayscale\n",
        "* convert to tensor\n",
        "* normalization\n",
        "\n",
        "We then load the images in dataloader. The batch size from above is passed here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbtbmHs8bh1G"
      },
      "source": [
        "train_ds_norm = ImageFolder('./dataset/chest_xray/chest_xray_normal/', transform=T.Compose([ T.Resize(image_size),                       \n",
        "                                                        T.CenterCrop(image_size),\n",
        "                                                        T.transforms.Grayscale(num_output_channels=1),   \n",
        "                                                        T.ToTensor(),\n",
        "                                                        T.Normalize(*stats)]))\n",
        "train_dl_norm = DataLoader(train_ds_norm, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "train_ds_pneum = ImageFolder('./dataset/chest_xray/chest_xray_pneumonia/', transform=T.Compose([ T.Resize(image_size),                       \n",
        "                                                        T.CenterCrop(image_size),\n",
        "                                                        T.transforms.Grayscale(num_output_channels=1),   \n",
        "                                                        T.ToTensor(),\n",
        "                                                        T.Normalize(*stats)]))\n",
        "train_dl_pneum = DataLoader(train_ds_pneum, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuD__Dcjezse"
      },
      "source": [
        "We now create some functions to help visualize our data. This will let us see our progress as images are being generated, as well as being able to viewing a large batch of images at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1DUvhQzd7Xk"
      },
      "source": [
        "def denorm(tensors):\n",
        "    return tensors * stats[1] + stats[0]\n",
        "\n",
        "def show_images(images, nmax=images_count):\n",
        "    grid = make_grid(\n",
        "        denorm(\n",
        "            images.cpu().detach()[:nmax]\n",
        "        ), nrow=images_row_count)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(grid.permute(1, 2, 0))\n",
        "\n",
        "def show_batch(dl, nmax=images_count):\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eccdHlbfn6l"
      },
      "source": [
        "We can visualize our current dataset using the methods above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UxLz-mVcDPn"
      },
      "source": [
        "show_batch(train_dl_norm)\n",
        "show_batch(train_dl_pneum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgFCoVh8mX71"
      },
      "source": [
        "### Preparing the Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9ba4RVc-mtP"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b-Ge5qgfmN8"
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Tgp2POgKeX"
      },
      "source": [
        "We can now verify that we have a gpu available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBOtFQCYgNDT"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pys5b6tugQBQ"
      },
      "source": [
        "train_dl_norm = DeviceDataLoader(train_dl_norm, device)\n",
        "train_dl_pneum = DeviceDataLoader(train_dl_pneum, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM6uZ0e5gXK0"
      },
      "source": [
        "discriminator_norm = nn.Sequential(\n",
        "    # input shape = 1 x 128 x 128\n",
        "\n",
        "    nn.Conv2d(1, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    #  output shape = 128 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 256 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 512 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 1024 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(1024, 2048, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(2048),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 2048 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(2048, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # output shape = 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "discriminator_pneum = nn.Sequential(\n",
        "    # input shape = 1 x 128 x 128\n",
        "\n",
        "    nn.Conv2d(1, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    #  output shape = 128 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 256 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 512 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 1024 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(1024, 2048, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(2048),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # output shape = 2048 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(2048, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # output shape = 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSAoCLshwIk"
      },
      "source": [
        "discriminator_norm = to_device(discriminator_norm, device)\n",
        "discriminator_pneum = to_device(discriminator_pneum, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxvcpJdCh1Nz"
      },
      "source": [
        "latent_size = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHA3InB5h9lu"
      },
      "source": [
        "generator_norm = nn.Sequential(\n",
        "    # input shape =  latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 2048, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(2048),\n",
        "    nn.ReLU(True),\n",
        "    #output shape = 2048 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 1024 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 512 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 256 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 128 x 64 x 64\n",
        "\n",
        "    nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # output shape = 1 x 128 x 128\n",
        ")\n",
        "\n",
        "generator_pneum = nn.Sequential(\n",
        "    # input shape =  latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 2048, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(2048),\n",
        "    nn.ReLU(True),\n",
        "    #output shape = 2048 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 1024 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 512 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 256 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # output shape = 128 x 64 x 64\n",
        "\n",
        "    nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # output shape = 1 x 128 x 128\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahmuk2pKjQaJ"
      },
      "source": [
        "generator_norm = to_device(generator_norm, device)\n",
        "generator_pneum = to_device(generator_pneum, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCqQhXuoix0S"
      },
      "source": [
        "We can then generate a batch of latent tensors to generate random image against both the normal and pneumonia generators. Since they are untrained, they will appear as noise for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFwoOssHiJ3R"
      },
      "source": [
        "random_latent_tensors = torch.randn(images_count, latent_size, 1, 1, device=device)\n",
        "imgs_norm = generator_norm(random_latent_tensors)\n",
        "imgs_pneum = generator_pneum(random_latent_tensors)\n",
        "\n",
        "show_images(imgs_norm)\n",
        "show_images(imgs_pneum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq-1fSIfjCIF"
      },
      "source": [
        "We can now verify the shapes are correct. The generator correctly outputs 128x128 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Ss-iZ3iqDQ"
      },
      "source": [
        "print(imgs_norm.shape)\n",
        "print(imgs_pneum.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH8qeCeejBdU"
      },
      "source": [
        "def train_discriminator(real_images, opt_d, discriminator, generator):\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    real_preds = discriminator(real_images)\n",
        "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "    fake_preds = discriminator(fake_images)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxHNJrjvjsTP"
      },
      "source": [
        "def train_generator(opt_g, discriminator, generator):\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-QnwE8OjuP5"
      },
      "source": [
        "os.makedirs('generated/normal', exist_ok=True)\n",
        "os.makedirs('generated/pneumonia', exist_ok=True)\n",
        "os.makedirs('epochs/normal', exist_ok=True)\n",
        "os.makedirs('epochs/pneumonia', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqqIK7G9j3LI"
      },
      "source": [
        "def save_samples(index, latent_tensors, generator, path, show=True):\n",
        "    imgs = generator(latent_tensors)\n",
        "    file_name = 'xray-{0:0=5d}.png'.format(index)\n",
        "    save_image(denorm(imgs), os.path.join(path, file_name), nrow=8)\n",
        "\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(16, 16))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(imgs.cpu().detach(), nrow=images_row_count).permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMzxIZjZj_Hc"
      },
      "source": [
        "fixed_latent = torch.randn(images_count, latent_size, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUG3FX7vkDpd"
      },
      "source": [
        "save_samples(0, fixed_latent, generator_norm, 'epochs/normal')\n",
        "save_samples(0, fixed_latent, generator_pneum, 'epochs/pneumonia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56a5BQqVlR6s"
      },
      "source": [
        "lr_g = 0.0005\n",
        "lr_d = 0.00005\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujqbPNx4BBve"
      },
      "source": [
        "#### Setup Weights and Biases To Analyze the Model in Real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dfroQx3BI6X"
      },
      "source": [
        "! pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sqk3MuSYGPea"
      },
      "source": [
        "!wandb login\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mpCJYgawkEuV"
      },
      "source": [
        "def fit(epochs, lr_g, lr_d, discriminator, generator, path, train_dl, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "\n",
        "    # Create optimizers\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
        "\n",
        "    config_defaults = {\n",
        "      'epochs': epochs,\n",
        "      'batch_size': batch_size,\n",
        "      'learning_rate': lr_g,\n",
        "      'optimizer': 'adam',\n",
        "      'fc_layer_size': 128,\n",
        "    }\n",
        "\n",
        "    wandb.init(project='xray-data-{}'.format(path), config=config_defaults)\n",
        "    try:\n",
        "      wandb.watch(generator)\n",
        "    except:\n",
        "      print(\"Error watching model, ignoring.\")\n",
        "\n",
        "    config = wandb.config\n",
        "    config.learning_rate = lr_g\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            # Train discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d, discriminator, generator)\n",
        "            # Train generator\n",
        "            loss_g = train_generator(opt_g, discriminator, generator)\n",
        "            \n",
        "        # Record losses & scores\n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "\n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "        save_samples(epoch+start_idx, fixed_latent, generator, 'epochs/' + path, show=False)\n",
        "\n",
        "        imgs = generator(fixed_latent)\n",
        "        wandb.log({\n",
        "          \"generator loss\": loss_g,\n",
        "          \"discriminator loss\": loss_d,\n",
        "          \"real score\": real_score,\n",
        "          \"fake score\": fake_score,\n",
        "          \"examples\" : [wandb.Image(i) for i in imgs],\n",
        "        }, step=epoch)\n",
        "    \n",
        "    return losses_g, losses_d, real_scores, fake_scores, opt_d, opt_g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Hts4a5lh7S"
      },
      "source": [
        "norm_history = fit(epochs, lr_g, lr_d, discriminator_norm, generator_norm, 'normal', train_dl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLBcjkZ-lsJx"
      },
      "source": [
        "pneum_history = fit(epochs, lr_g, lr_d, discriminator_pneum, generator_pneum, 'pneumonia', train_dl_pneum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJIbw9pmsV_"
      },
      "source": [
        "os.makedirs('models/', exist_ok=True)\n",
        "torch.save(discriminator_norm.state_dict(), 'models/discriminator_norm.pt')\n",
        "torch.save(discriminator_pneum.state_dict(), 'models/discriminator_pnuem.pt')\n",
        "torch.save(generator_norm.state_dict(), 'models/generator_norm.pt')\n",
        "torch.save(generator_pneum.state_dict(), 'models/generator_pnuem.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxQnOkDf4W-f"
      },
      "source": [
        "losses_g_norm, losses_d_norm, real_scores_norm, fake_scores_norm, opt_d_norm, opt_g_norm = norm_history\n",
        "losses_g_pneum, losses_d_pneum, real_scores_pneum, fake_scores_pneum, opt_d_pneum, opt_g_pneum = pneum_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkudNhuq2vir"
      },
      "source": [
        "torch.save({\n",
        "  'discriminator_norm_state_dict': discriminator_norm.state_dict(),\n",
        "  'discriminator_pnuem_state_dict': discriminator_pneum.state_dict(),\n",
        "  'generator_norm_state_dict': generator_norm.state_dict(),\n",
        "  'generator_pnuem_state_dict': generator_pneum.state_dict(),\n",
        "  'generator_optim_norm_state_dict': opt_g_norm.state_dict(),\n",
        "  'generator_optim_pnuem_state_dict': opt_g_pnuem.state_dict(),\n",
        "  'discriminator_optim_norm_state_dict': opt_d_norm.state_dict(),\n",
        "  'discriminator_optim_pnuem_state_dict': opt_d_pnuem.state_dict(),\n",
        "  epoch: epochs,\n",
        "}, 'models/gan.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4EiQmfq1QoP"
      },
      "source": [
        "! rm -rf 'drive/MyDrive/chest_xrays/artifacts/'\n",
        "artifacts_dir = 'drive/MyDrive/chest_xrays/artifacts/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsaSu_CE0n-y"
      },
      "source": [
        "os.makedirs(artifacts_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Y2kB1i1DKM"
      },
      "source": [
        "! cp -r epochs/ drive/MyDrive/chest_xrays/artifacts/epochs/\n",
        "! cp -r models/ drive/MyDrive/chest_xrays/artifacts/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZwSyXhUM-zX"
      },
      "source": [
        "def generate_images(num, generator, path, name):\n",
        "    for i in range(num):\n",
        "      random_latent_tensors = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "      imgs = generator(random_latent_tensors)\n",
        "      file_name = 'generated-xray-{0:0=5d}-{1}.png'.format(i+1, name)\n",
        "      save_image(denorm(imgs.cpu().detach()[:1]), os.path.join(path, file_name), nrow=1)\n",
        "      print('saving {}/{}'.format(i+1, num))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "royC8fVoN2UE"
      },
      "source": [
        "generate_images(5000, generator_norm, 'generated/normal/', 'normal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJg45crulmZG"
      },
      "source": [
        "generate_images(5000, generator_pneum, 'generated/pneumonia/', 'pneumonia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhf2ySqGPCwA"
      },
      "source": [
        "! cp -r generated/ drive/MyDrive/chest_xrays/artifacts/generated/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avl1bWYD2fjC"
      },
      "source": [
        "random_latent_tensors = torch.randn(128, latent_size, 1, 1, device=device)\n",
        "imgs_norm = generator_norm(random_latent_tensors)\n",
        "imgs_pneum = generator_pneum(random_latent_tensors)\n",
        "\n",
        "show_images(imgs_norm, 1)\n",
        "show_images(imgs_pneum, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}